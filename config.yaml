openai:
  generate_model: gpt-4o-mini
  eval_model: gpt-4o

load_data:
  n_samples: 1000
  raw_path: data/raw/webtext/openwebtext_sample.jsonl
  hf_streaming_name: stas/openwebtext-10k
  hf_split: train

clean_data:
  webtext:
    input_folder_list: [data/labeled/webtext]
    output_path: data/labeled/clean_label_openwebtext_sample.jsonl
  generated:
    input_folder_list: [data/labeled/generated]
    output_path: data/labeled/clean_label_generated_sample.jsonl
  combined:
    input_folder_list: [data/labeled/webtext, data/labeled/generated]
    output_path: data/labeled/clean_label_all_sample.jsonl

split_data:
  input: data/labeled/clean_label_all_sample.jsonl
  output_dir: data
  stratified_criteria: [formality, enthusiasm, empathy]
  threshold: 6
  train_ratio: 0.8
  val_ratio: 0.1

raw_transcripts_gen:
  num_samples: 50
  output_folder: data/raw/generated

gt_label:
  webtext:
    input_folder: data/raw/webtext
    output_folder: data/labeled/webtext
  generated:
    input_folder: data/raw/generated
    output_folder: data/labeled/generated

llm_label:
  model: Qwen/Qwen2.5-3B-Instruct
  adapter: False
  use_ray: True
  input_test_path: /mnt/cluster_storage/llm-fine-tune-ray/data/test/clean_label_all_sample_test.jsonl
  pretrain:
    output_folder: /mnt/cluster_storage/llm-fine-tune-ray/predictions/pretrain
  fine_tune:
    input_adapter_folder: /mnt/cluster_storage/llm-fine-tune-ray/checkpoints_ray/TorchTrainer_2025-06-23_16-16-31/TorchTrainer_19362_00000_0_2025-06-23_16-16-31/checkpoint_000000
    output_folder: /mnt/cluster_storage/llm-fine-tune-ray/predictions/fine_tune

fine_tune:
  data_path:
    train: /mnt/cluster_storage/llm-fine-tune-ray/data/train/clean_label_all_sample_train.jsonl
    val: /mnt/cluster_storage/llm-fine-tune-ray/data/val/clean_label_all_sample_val.jsonl
    test: /mnt/cluster_storage/llm-fine-tune-ray/data/test/clean_label_all_sample_test.jsonl
  output_path: /mnt/cluster_storage/llm-fine-tune-ray/checkpoints

criteria: [formality, persuasiveness, enthusiasm, empathy, filler words, transition logic]

evaluation:
  # jsonl_format_in: 
  #   [data/labeled/label_openwebtext_sample.jsonl,
  #   data/labeled/generated/label_generated_bad_transition_logic.jsonl,
  #   data/labeled/generated/label_generated_bad_formality.jsonl,
  #   data/labeled/generated/label_generated_bad_persuasion.jsonl,
  #   data/labeled/generated/label_generated_bad_filler_words.jsonl]
  
  # jsonl_format_in: [predictions/pretrain/spretrain_predictions_ray.jsonl, predictions/fine_tune/fine_tune_predictions_epoch1.jsonl, predictions/fine_tune/fine_tune_predictions_epoch2.jsonl, predictions/fine_tune/fine_tune_predictions_epoch3.jsonl, data/test/clean_label_all_sample_test.jsonl]
  jsonl_format_in: [/mnt/cluster_storage/llm-fine-tune-ray/predictions/pretrain/pretrain_predictions.jsonl, /mnt/cluster_storage/llm-fine-tune-ray/predictions/fine_tune/sfine_tune_predictions_epoch1_ray.jsonl, /mnt/cluster_storage/llm-fine-tune-ray/data/test/clean_label_all_sample_test.jsonl]
  # jsonl_format_in: [predictions/pretrain/pretrain_predictions.jsonl, data/test/clean_label_all_sample_test.jsonl]
  jsonl_format_out: eval/evaluation_metrics1.txt
  mse: True
  score_threshold: [6]